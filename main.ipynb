{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from trainer import Trainer\n",
    "from transformers import AdamW\n",
    "import json\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# python load data\n",
    "from utils.pre_processing import combine_scraped_data\n",
    "from config import DATA_PATHS\n",
    "from utils.pre_processing import labels_indexes_mapping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for phase in DATA_PATHS:\n",
    "    metadata_name = DATA_PATHS[phase]['metadata']\n",
    "    data_name = DATA_PATHS[phase]['data']\n",
    "    combine_scraped_data(f'data/{data_name}', f'data/{metadata_name}', is_train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from utils.pre_processing import clean_scraped_data_to_code\n",
    "# TRAIN\n",
    "train_base = clean_scraped_data_to_code('data/train_processed.xlsx')\n",
    "# TEST\n",
    "test = clean_scraped_data_to_code('data/test_processed.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def clean_label_code(code: str) -> str:\n",
    "    return code.split('.')[0][:-2]\n",
    "\n",
    "train_base.loc[:, 'labels'] = train_base.labels.apply(clean_label_code)\n",
    "test.loc[:, 'labels'] = test.labels.apply(clean_label_code)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data exploration"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "24    2117\n25    1648\n21    1430\n33    1426\n52     932\n31     839\n12     555\n23     494\n83     480\n93     480\n14     398\n72     372\n51     303\n43     291\n13     286\n42     275\n35     274\n94     271\n41     246\n26     243\n81     220\n91     210\n75     191\n44     185\n34     171\n22     155\n74     146\n32     141\n82     109\n53     107\n71      98\n92      85\n54      75\n11      66\n73      51\n96      45\n61      31\n95       5\n62       4\n01       3\n02       3\n03       2\nName: labels, dtype: int64"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels distribution\n",
    "train_base.labels.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create train, val, test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# # apply the label\n",
    "# train_base.labels = train_base.labels.apply(lambda l: 'other' if l in low_freq_labels else l)\n",
    "# test.labels = test.labels.apply(lambda l: 'other' if l in low_freq_labels else l)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "((11597, 2), (3866, 2))"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, val = train_test_split(train_base, test_size=0.25, shuffle=True, random_state=11)\n",
    "train.shape, val.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from utils.pre_processing import labels_indexes_mapping\n",
    "label_to_idx, idx_to_label = labels_indexes_mapping(train_base)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "((11597, 2), (3866, 2), (15463, 2))"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert all string labels to number in order to train\n",
    "from utils.pre_processing import labels_indexes_mapping\n",
    "label_to_idx, idx_to_label = labels_indexes_mapping(train_base)\n",
    "\n",
    "train.loc[:, 'labels'] = train.loc[:, 'labels'].apply(lambda x: label_to_idx.get(x))\n",
    "val.loc[:, 'labels'] = val.labels.apply(lambda x: label_to_idx.get(x))\n",
    "test.loc[:, 'labels'] = test.labels.apply(lambda x: label_to_idx.get(x))\n",
    "train.shape, val.shape, test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# convert the data to pytorch dataset\n",
    "from datasets import TitlesDataset\n",
    "\n",
    "train_ds = TitlesDataset(train.title.tolist(), train.labels.tolist())\n",
    "val_ds = TitlesDataset(val.title.tolist(), val.labels.tolist())\n",
    "test_ds = TitlesDataset(test.title.tolist(), test.labels.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 16\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, shuffle=True, batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_ds, shuffle=True, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_ds, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter optimization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import f1_score\n",
    "from models import BERT, tBERT\n",
    "from utils.pre_processing import create_titles_corpus\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "N_TRAILS = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-08-06 17:05:23,072]\u001B[0m A new study created in memory with name: no-name-2a7c45a1-5fb0-4d79-8c74-6be52fa80f92\u001B[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/725 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68da0e1ebfc84005a742c26bc33ee064"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/242 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0731b170be8c4d6bbe46d2b9d35a0716"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-08-06 17:06:57,909]\u001B[0m Trial 0 finished with value: 0.4477496120020693 and parameters: {'embeddings_length': 64, 'lr': 0.0008525880501640893}. Best is trial 0 with value: 0.4477496120020693.\u001B[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'list' object is not a mapping",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [50]\u001B[0m, in \u001B[0;36m<cell line: 22>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     21\u001B[0m trail_ \u001B[38;5;241m=\u001B[39m study\u001B[38;5;241m.\u001B[39mbest_trial\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresults/BERT_best_params.json\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m---> 23\u001B[0m     d \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtrail_\u001B[38;5;241m.\u001B[39mparams, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtrail_\u001B[38;5;241m.\u001B[39mvalues}\n\u001B[0;32m     24\u001B[0m     json\u001B[38;5;241m.\u001B[39mdump(d, f, indent\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBEST TRAIL:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m f1:  \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrail_\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mparams: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrail_\u001B[38;5;241m.\u001B[39mparams\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mTypeError\u001B[0m: 'list' object is not a mapping"
     ]
    }
   ],
   "source": [
    "def bert_objective(trail):\n",
    "    # Params ranges:\n",
    "    embeddings_length = trail.suggest_categorical('embeddings_length', [32, 64])\n",
    "    lr = trail.suggest_loguniform('lr', 1e-6, 1e-3)\n",
    "\n",
    "    model = BERT(model_name='bert-base-uncased',num_labels=len(label_to_idx),\n",
    "             max_length=embeddings_length, device=DEVICE)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    trainer = Trainer(model=model, optimizer=optimizer, train_dataloader=train_dataloader, num_epochs=1, device=DEVICE)\n",
    "\n",
    "    trainer.train()\n",
    "    labels, preds = trainer.evaluate(val_dataloader)\n",
    "    f1 = f1_score(labels, preds, average='micro')\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(bert_objective, n_trials=N_TRAILS)\n",
    "\n",
    "trail_ = study.best_trial\n",
    "with open('results/BERT_best_params.json', 'w') as f:\n",
    "    d = dict(trail_.params)\n",
    "    d['f1'] = trail_.values[0]\n",
    "    json.dump(d, f, indent=4)\n",
    "print(f'BEST TRAIL:\\n f1:  {trail_.values}\\nparams: {trail_.params}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-08-06 16:58:21,023]\u001B[0m A new study created in memory with name: no-name-92186d83-eabf-4380-aa72-d595a9966cb1\u001B[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/725 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04fa72280c8743a7bdde7acf65b8b4fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/242 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf4f5e4a963a4e2ea5873f1fece86977"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-08-06 17:02:17,354]\u001B[0m Trial 0 finished with value: 0.2909984480082773 and parameters: {'embeddings_length': 64, 'lr': 5.639469575148213e-05, 'n_topics': 69, 'alpha': 8.65564170855882}. Best is trial 0 with value: 0.2909984480082773.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST TRAIL:\n",
      " f1:  [0.2909984480082773]\n",
      "params: {'embeddings_length': 64, 'lr': 5.639469575148213e-05, 'n_topics': 69, 'alpha': 8.65564170855882}\n"
     ]
    }
   ],
   "source": [
    "def tbert_objective(trail):\n",
    "    # PARAMS SETTING\n",
    "    # Embedding\n",
    "    embeddings_length = trail.suggest_categorical('embeddings_length', [32, 64])\n",
    "    # General Model\n",
    "    lr = trail.suggest_loguniform('lr', 1e-6, 1e-3)\n",
    "    # LDA\n",
    "    n_topics = trail.suggest_int('n_topics', 50, 100)\n",
    "    alpha = trail.suggest_float('alpha', 1/50, 10)\n",
    "\n",
    "\n",
    "    corpus = create_titles_corpus(train_dataloader)\n",
    "    model = tBERT(corpus, model_name='bert-base-uncased',num_labels=len(label_to_idx),\n",
    "             max_length=embeddings_length, n_topics=n_topics, alpha=alpha, device=DEVICE)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    trainer = Trainer(model=model, optimizer=optimizer, train_dataloader=train_dataloader, num_epochs=1, device=DEVICE)\n",
    "\n",
    "    trainer.train()\n",
    "    labels, preds = trainer.evaluate(val_dataloader)\n",
    "    f1 = f1_score(labels, preds, average='micro')\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(tbert_objective, n_trials=N_TRAILS)\n",
    "\n",
    "trail_ = study.best_trial\n",
    "with open('results/tBERT_best_params.json', 'w') as f:\n",
    "    d = dict(trail_.params)\n",
    "    d['f1'] = trail_.values[0]\n",
    "    json.dump(d, f, indent=4)\n",
    "print(f'BEST TRAIL:\\n f1:  {trail_.values}\\nparams: {trail_.params}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}